{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a42327d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-29T17:58:25.712175Z",
     "iopub.status.busy": "2025-07-29T17:58:25.711886Z",
     "iopub.status.idle": "2025-07-29T17:58:29.813230Z",
     "shell.execute_reply": "2025-07-29T17:58:29.812364Z"
    },
    "papermill": {
     "duration": 4.107073,
     "end_time": "2025-07-29T17:58:29.815144",
     "exception": false,
     "start_time": "2025-07-29T17:58:25.708071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\r\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\r\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\r\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (7.34.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\r\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\r\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\r\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.4)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\r\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\r\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython) (0.19.2)\r\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython) (0.7.5)\r\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython) (5.7.1)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython) (3.0.51)\r\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython) (2.19.2)\r\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython) (0.2.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython) (0.1.7)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython) (4.9.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython) (0.8.4)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\r\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\r\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython) (0.7.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy librosa scikit-learn tensorflow matplotlib ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c0f9f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T17:58:29.822324Z",
     "iopub.status.busy": "2025-07-29T17:58:29.822059Z",
     "iopub.status.idle": "2025-07-29T17:58:44.653742Z",
     "shell.execute_reply": "2025-07-29T17:58:44.652936Z"
    },
    "papermill": {
     "duration": 14.836975,
     "end_time": "2025-07-29T17:58:44.655232",
     "exception": false,
     "start_time": "2025-07-29T17:58:29.818257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 17:58:32.367970: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753811912.564350      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753811912.621370      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Bidirectional, LSTM, TimeDistributed, Reshape, BatchNormalization, Activation, Multiply, Permute, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from IPython.display import Audio, display\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f44cab7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T17:58:44.661971Z",
     "iopub.status.busy": "2025-07-29T17:58:44.661517Z",
     "iopub.status.idle": "2025-07-29T17:58:44.665188Z",
     "shell.execute_reply": "2025-07-29T17:58:44.664639Z"
    },
    "papermill": {
     "duration": 0.008077,
     "end_time": "2025-07-29T17:58:44.666241",
     "exception": false,
     "start_time": "2025-07-29T17:58:44.658164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "SR = 22050\n",
    "DURATION = 2.5\n",
    "SAMPLES_PER_TRACK = int(SR * DURATION)\n",
    "N_MELS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b6e906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T17:58:44.672016Z",
     "iopub.status.busy": "2025-07-29T17:58:44.671779Z",
     "iopub.status.idle": "2025-07-29T17:58:44.676409Z",
     "shell.execute_reply": "2025-07-29T17:58:44.675871Z"
    },
    "papermill": {
     "duration": 0.008596,
     "end_time": "2025-07-29T17:58:44.677400",
     "exception": false,
     "start_time": "2025-07-29T17:58:44.668804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION FUNCTION\n",
    "def extract_features(file_path):\n",
    "    try:\n",
    "        signal, sr = librosa.load(file_path, sr=SR)\n",
    "        if len(signal) < SAMPLES_PER_TRACK:\n",
    "            pad_length = SAMPLES_PER_TRACK - len(signal)\n",
    "            signal = np.pad(signal, (0, pad_length))\n",
    "        else:\n",
    "            signal = signal[:SAMPLES_PER_TRACK]\n",
    "        mel = librosa.feature.melspectrogram(y=signal, sr=SR, n_mels=N_MELS)\n",
    "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        mel_db = (mel_db - np.mean(mel_db)) / (np.std(mel_db) + 1e-6)  # Normalization\n",
    "        return mel_db\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a0fae35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T17:58:44.683165Z",
     "iopub.status.busy": "2025-07-29T17:58:44.682956Z",
     "iopub.status.idle": "2025-07-29T18:00:05.591030Z",
     "shell.execute_reply": "2025-07-29T18:00:05.590267Z"
    },
    "papermill": {
     "duration": 80.915001,
     "end_time": "2025-07-29T18:00:05.594902",
     "exception": false,
     "start_time": "2025-07-29T17:58:44.679901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution: Counter({'surprised': 384, 'disgust': 384, 'fearful': 384, 'sad': 384, 'calm': 384, 'happy': 384, 'angry': 384, 'neutral': 192})\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA FROM RAVDESS\n",
    "data_dir = '/kaggle/input/ravdess-emotional-speech-audio'\n",
    "emotion_labels = {\n",
    "    '01': 'neutral', '02': 'calm', '03': 'happy', '04': 'sad',\n",
    "    '05': 'angry', '06': 'fearful', '07': 'disgust', '08': 'surprised'\n",
    "}\n",
    "\n",
    "X, y = [], []\n",
    "file_paths = []\n",
    "\n",
    "for root, _, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            emotion_code = file.split(\"-\")[2]\n",
    "            emotion = emotion_labels.get(emotion_code)\n",
    "            if emotion:\n",
    "                features = extract_features(file_path)\n",
    "                if features is not None:\n",
    "                    X.append(features)\n",
    "                    y.append(emotion)\n",
    "                    file_paths.append(file_path)\n",
    "\n",
    "print(\"Label Distribution:\", Counter(y))\n",
    "\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f73732c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T18:00:05.601477Z",
     "iopub.status.busy": "2025-07-29T18:00:05.601038Z",
     "iopub.status.idle": "2025-07-29T18:03:15.139778Z",
     "shell.execute_reply": "2025-07-29T18:03:15.138953Z"
    },
    "papermill": {
     "duration": 189.545899,
     "end_time": "2025-07-29T18:03:15.143530",
     "exception": false,
     "start_time": "2025-07-29T18:00:05.597631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution After Augmentation: Counter({'surprised': 1536, 'disgust': 1536, 'fearful': 1536, 'sad': 1536, 'calm': 1536, 'happy': 1536, 'angry': 1536, 'neutral': 768})\n"
     ]
    }
   ],
   "source": [
    "# DATA AUGMENTATION\n",
    "def add_noise(signal, noise_factor=0.005):\n",
    "    noise = np.random.randn(len(signal))\n",
    "    return signal + noise_factor * noise\n",
    "\n",
    "def time_stretch(signal, rate=0.8):\n",
    "    return librosa.effects.time_stretch(signal, rate=rate)\n",
    "\n",
    "def pitch_shift(signal, sr, n_steps=2):\n",
    "    return librosa.effects.pitch_shift(signal, sr=sr, n_steps=n_steps)\n",
    "\n",
    "augmented_X, augmented_y = [], []\n",
    "for i in range(len(file_paths)):\n",
    "    path = file_paths[i]\n",
    "    label = y[i]\n",
    "    signal, sr = librosa.load(path, sr=SR)\n",
    "\n",
    "    signal = signal[:SAMPLES_PER_TRACK] if len(signal) > SAMPLES_PER_TRACK else np.pad(signal, (0, SAMPLES_PER_TRACK - len(signal)))\n",
    "\n",
    "    for augment_fn in [\n",
    "        lambda s: add_noise(s),\n",
    "        lambda s: time_stretch(s, rate=0.9),\n",
    "        lambda s: pitch_shift(s, sr=SR, n_steps=2)\n",
    "    ]:\n",
    "        try:\n",
    "            augmented_signal = augment_fn(signal)\n",
    "            augmented_signal = augmented_signal[:SAMPLES_PER_TRACK] if len(augmented_signal) > SAMPLES_PER_TRACK else np.pad(augmented_signal, (0, SAMPLES_PER_TRACK - len(augmented_signal)))\n",
    "            mel = librosa.feature.melspectrogram(y=augmented_signal, sr=SR, n_mels=N_MELS)\n",
    "            mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "            mel_db = (mel_db - np.mean(mel_db)) / (np.std(mel_db) + 1e-6)\n",
    "            augmented_X.append(mel_db)\n",
    "            augmented_y.append(label)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "X = np.concatenate([X, np.expand_dims(np.array(augmented_X), -1)], axis=0)\n",
    "y += augmented_y\n",
    "\n",
    "print(\"Label Distribution After Augmentation:\", Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6d5b1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T18:03:15.151309Z",
     "iopub.status.busy": "2025-07-29T18:03:15.150808Z",
     "iopub.status.idle": "2025-07-29T18:03:15.157841Z",
     "shell.execute_reply": "2025-07-29T18:03:15.157329Z"
    },
    "papermill": {
     "duration": 0.012383,
     "end_time": "2025-07-29T18:03:15.158817",
     "exception": false,
     "start_time": "2025-07-29T18:03:15.146434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ENCODE LABELS\n",
    "le = LabelEncoder()\n",
    "y_int = le.fit_transform(y)\n",
    "y_encoded = to_categorical(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a818b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T18:03:15.165155Z",
     "iopub.status.busy": "2025-07-29T18:03:15.164950Z",
     "iopub.status.idle": "2025-07-29T18:03:15.172168Z",
     "shell.execute_reply": "2025-07-29T18:03:15.171511Z"
    },
    "papermill": {
     "duration": 0.011623,
     "end_time": "2025-07-29T18:03:15.173244",
     "exception": false,
     "start_time": "2025-07-29T18:03:15.161621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.9375, 1: 0.9375, 2: 0.9375, 3: 0.9375, 4: 0.9375, 5: 1.875, 6: 0.9375, 7: 0.9375}\n"
     ]
    }
   ],
   "source": [
    "# CLASS WEIGHTS\n",
    "class_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y_int), y=y_int)\n",
    "class_weights = dict(enumerate(class_weights_array))\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7963d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T18:03:15.179647Z",
     "iopub.status.busy": "2025-07-29T18:03:15.179454Z",
     "iopub.status.idle": "2025-07-29T18:03:15.546316Z",
     "shell.execute_reply": "2025-07-29T18:03:15.545259Z"
    },
    "papermill": {
     "duration": 0.371678,
     "end_time": "2025-07-29T18:03:15.547702",
     "exception": false,
     "start_time": "2025-07-29T18:03:15.176024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (9216, 128, 108, 1) (9216, 8)\n",
      "Test shape: (2304, 128, 108, 1) (2304, 8)\n"
     ]
    }
   ],
   "source": [
    "# SPLIT DATA\n",
    "X_train, X_test, y_train, y_test, y_train_int, y_test_int = train_test_split(\n",
    "    X, y_encoded, y_int, test_size=0.2, random_state=42, stratify=y_int\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fc8ebb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T18:03:15.555512Z",
     "iopub.status.busy": "2025-07-29T18:03:15.555299Z",
     "iopub.status.idle": "2025-07-29T18:03:17.693714Z",
     "shell.execute_reply": "2025-07-29T18:03:17.693038Z"
    },
    "papermill": {
     "duration": 2.14358,
     "end_time": "2025-07-29T18:03:17.694865",
     "exception": false,
     "start_time": "2025-07-29T18:03:15.551285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753812196.355171      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1753812196.355792      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_vec       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ attention_vec[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110592</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110592</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">14,155,904</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m108\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m108\u001b[0m,  │        \u001b[38;5;34m320\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m108\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m108\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m54\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m54\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m54\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m54\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m54\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m27\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m27\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m864\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m864\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m66,048\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_vec       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m864\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m16,512\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m864\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ attention_vec[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110592\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110592\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │ \u001b[38;5;34m14,155,904\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │      \u001b[38;5;34m1,032\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,258,696</span> (54.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,258,696\u001b[0m (54.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,258,504</span> (54.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,258,504\u001b[0m (54.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CRNN MODEL WITH FIXED ATTENTION\n",
    "def attention_layer(inputs):\n",
    "    time_steps = int(inputs.shape[1])\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    attention_probs = Dense(input_dim, activation='softmax', name='attention_vec')(inputs)\n",
    "    attention_mul = Multiply()([inputs, attention_probs])\n",
    "    return attention_mul\n",
    "\n",
    "input_shape = (X.shape[1], X.shape[2], 1)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Reshape for LSTM\n",
    "x = Reshape((x.shape[1] * x.shape[2], x.shape[3]))(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = attention_layer(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(len(np.unique(y_int)), activation='softmax')(x)\n",
    "\n",
    "emotion_model = Model(inputs, outputs)\n",
    "emotion_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "emotion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01aea386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T18:03:17.704036Z",
     "iopub.status.busy": "2025-07-29T18:03:17.703503Z",
     "iopub.status.idle": "2025-07-29T18:27:10.421188Z",
     "shell.execute_reply": "2025-07-29T18:27:10.420451Z"
    },
    "papermill": {
     "duration": 1432.723328,
     "end_time": "2025-07-29T18:27:10.422580",
     "exception": false,
     "start_time": "2025-07-29T18:03:17.699252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1753812204.680405      19 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "I0000 00:00:1753812205.014056      76 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.2610 - loss: 1.8681\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50564, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 100ms/step - accuracy: 0.2614 - loss: 1.8673 - val_accuracy: 0.5056 - val_loss: 1.3378 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5774 - loss: 1.1292\n",
      "Epoch 2: val_accuracy improved from 0.50564 to 0.72352, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.5775 - loss: 1.1289 - val_accuracy: 0.7235 - val_loss: 0.8063 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7379 - loss: 0.7129\n",
      "Epoch 3: val_accuracy improved from 0.72352 to 0.80773, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - accuracy: 0.7380 - loss: 0.7127 - val_accuracy: 0.8077 - val_loss: 0.5221 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8326 - loss: 0.4780\n",
      "Epoch 4: val_accuracy improved from 0.80773 to 0.85938, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 101ms/step - accuracy: 0.8326 - loss: 0.4779 - val_accuracy: 0.8594 - val_loss: 0.4031 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8970 - loss: 0.3054\n",
      "Epoch 5: val_accuracy improved from 0.85938 to 0.90582, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - accuracy: 0.8970 - loss: 0.3054 - val_accuracy: 0.9058 - val_loss: 0.2920 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9364 - loss: 0.1934\n",
      "Epoch 6: val_accuracy improved from 0.90582 to 0.93099, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - accuracy: 0.9364 - loss: 0.1934 - val_accuracy: 0.9310 - val_loss: 0.2182 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9510 - loss: 0.1511\n",
      "Epoch 7: val_accuracy improved from 0.93099 to 0.94010, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 101ms/step - accuracy: 0.9510 - loss: 0.1511 - val_accuracy: 0.9401 - val_loss: 0.2040 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9625 - loss: 0.1239\n",
      "Epoch 8: val_accuracy improved from 0.94010 to 0.94835, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - accuracy: 0.9625 - loss: 0.1239 - val_accuracy: 0.9484 - val_loss: 0.1801 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9733 - loss: 0.0883\n",
      "Epoch 9: val_accuracy did not improve from 0.94835\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9733 - loss: 0.0883 - val_accuracy: 0.9479 - val_loss: 0.1772 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9774 - loss: 0.0762\n",
      "Epoch 10: val_accuracy did not improve from 0.94835\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9774 - loss: 0.0762 - val_accuracy: 0.9327 - val_loss: 0.2269 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9797 - loss: 0.0706\n",
      "Epoch 11: val_accuracy did not improve from 0.94835\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9797 - loss: 0.0707 - val_accuracy: 0.9332 - val_loss: 0.2240 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9829 - loss: 0.0592\n",
      "Epoch 12: val_accuracy improved from 0.94835 to 0.94878, saving model to emotion_detection_crnn_attention.h5\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - accuracy: 0.9829 - loss: 0.0592 - val_accuracy: 0.9488 - val_loss: 0.1900 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9903 - loss: 0.0377\n",
      "Epoch 13: val_accuracy improved from 0.94878 to 0.96181, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - accuracy: 0.9903 - loss: 0.0377 - val_accuracy: 0.9618 - val_loss: 0.1611 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9919 - loss: 0.0288\n",
      "Epoch 14: val_accuracy improved from 0.96181 to 0.96224, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - accuracy: 0.9919 - loss: 0.0288 - val_accuracy: 0.9622 - val_loss: 0.1597 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9924 - loss: 0.0238\n",
      "Epoch 15: val_accuracy did not improve from 0.96224\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9924 - loss: 0.0238 - val_accuracy: 0.9618 - val_loss: 0.1571 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9913 - loss: 0.0294\n",
      "Epoch 16: val_accuracy improved from 0.96224 to 0.96528, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - accuracy: 0.9913 - loss: 0.0294 - val_accuracy: 0.9653 - val_loss: 0.1548 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9935 - loss: 0.0252\n",
      "Epoch 17: val_accuracy did not improve from 0.96528\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9935 - loss: 0.0252 - val_accuracy: 0.9653 - val_loss: 0.1532 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9938 - loss: 0.0234\n",
      "Epoch 18: val_accuracy did not improve from 0.96528\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9938 - loss: 0.0234 - val_accuracy: 0.9601 - val_loss: 0.1665 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9941 - loss: 0.0225\n",
      "Epoch 19: val_accuracy did not improve from 0.96528\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9941 - loss: 0.0225 - val_accuracy: 0.9618 - val_loss: 0.1631 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9929 - loss: 0.0239\n",
      "Epoch 20: val_accuracy did not improve from 0.96528\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9929 - loss: 0.0239 - val_accuracy: 0.9583 - val_loss: 0.1763 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9968 - loss: 0.0126\n",
      "Epoch 21: val_accuracy did not improve from 0.96528\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9968 - loss: 0.0126 - val_accuracy: 0.9618 - val_loss: 0.1606 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9969 - loss: 0.0103\n",
      "Epoch 22: val_accuracy did not improve from 0.96528\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9969 - loss: 0.0103 - val_accuracy: 0.9605 - val_loss: 0.1656 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9981 - loss: 0.0090\n",
      "Epoch 23: val_accuracy did not improve from 0.96528\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9981 - loss: 0.0090 - val_accuracy: 0.9583 - val_loss: 0.1772 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9971 - loss: 0.0113\n",
      "Epoch 24: val_accuracy did not improve from 0.96528\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9971 - loss: 0.0113 - val_accuracy: 0.9640 - val_loss: 0.1662 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9975 - loss: 0.0091\n",
      "Epoch 25: val_accuracy did not improve from 0.96528\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9975 - loss: 0.0091 - val_accuracy: 0.9640 - val_loss: 0.1633 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9970 - loss: 0.0098\n",
      "Epoch 26: val_accuracy did not improve from 0.96528\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9970 - loss: 0.0098 - val_accuracy: 0.9631 - val_loss: 0.1656 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9987 - loss: 0.0071\n",
      "Epoch 27: val_accuracy did not improve from 0.96528\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9987 - loss: 0.0071 - val_accuracy: 0.9627 - val_loss: 0.1616 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9985 - loss: 0.0078\n",
      "Epoch 28: val_accuracy did not improve from 0.96528\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9985 - loss: 0.0078 - val_accuracy: 0.9648 - val_loss: 0.1579 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9981 - loss: 0.0068\n",
      "Epoch 29: val_accuracy did not improve from 0.96528\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9981 - loss: 0.0068 - val_accuracy: 0.9653 - val_loss: 0.1565 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9977 - loss: 0.0083\n",
      "Epoch 30: val_accuracy did not improve from 0.96528\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9977 - loss: 0.0083 - val_accuracy: 0.9648 - val_loss: 0.1591 - learning_rate: 3.1250e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9976 - loss: 0.0096\n",
      "Epoch 31: val_accuracy improved from 0.96528 to 0.96571, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - accuracy: 0.9976 - loss: 0.0095 - val_accuracy: 0.9657 - val_loss: 0.1610 - learning_rate: 3.1250e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9974 - loss: 0.0096\n",
      "Epoch 32: val_accuracy did not improve from 0.96571\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9974 - loss: 0.0096 - val_accuracy: 0.9644 - val_loss: 0.1634 - learning_rate: 3.1250e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9988 - loss: 0.0067\n",
      "Epoch 33: val_accuracy did not improve from 0.96571\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9988 - loss: 0.0067 - val_accuracy: 0.9648 - val_loss: 0.1645 - learning_rate: 1.5625e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9975 - loss: 0.0089\n",
      "Epoch 34: val_accuracy improved from 0.96571 to 0.96615, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - accuracy: 0.9975 - loss: 0.0089 - val_accuracy: 0.9661 - val_loss: 0.1627 - learning_rate: 1.5625e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9985 - loss: 0.0067\n",
      "Epoch 35: val_accuracy did not improve from 0.96615\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9985 - loss: 0.0067 - val_accuracy: 0.9657 - val_loss: 0.1647 - learning_rate: 1.5625e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9989 - loss: 0.0062\n",
      "Epoch 36: val_accuracy did not improve from 0.96615\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9989 - loss: 0.0062 - val_accuracy: 0.9657 - val_loss: 0.1636 - learning_rate: 7.8125e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9989 - loss: 0.0068\n",
      "Epoch 37: val_accuracy did not improve from 0.96615\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9989 - loss: 0.0068 - val_accuracy: 0.9653 - val_loss: 0.1636 - learning_rate: 7.8125e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9977 - loss: 0.0089\n",
      "Epoch 38: val_accuracy did not improve from 0.96615\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9977 - loss: 0.0089 - val_accuracy: 0.9657 - val_loss: 0.1615 - learning_rate: 7.8125e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9989 - loss: 0.0064\n",
      "Epoch 39: val_accuracy did not improve from 0.96615\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9989 - loss: 0.0064 - val_accuracy: 0.9657 - val_loss: 0.1610 - learning_rate: 3.9063e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9990 - loss: 0.0055\n",
      "Epoch 40: val_accuracy improved from 0.96615 to 0.96658, saving model to emotion_detection_crnn_attention.h5\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - accuracy: 0.9990 - loss: 0.0055 - val_accuracy: 0.9666 - val_loss: 0.1603 - learning_rate: 3.9063e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9988 - loss: 0.0074\n",
      "Epoch 41: val_accuracy did not improve from 0.96658\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9988 - loss: 0.0074 - val_accuracy: 0.9657 - val_loss: 0.1603 - learning_rate: 3.9063e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9979 - loss: 0.0077\n",
      "Epoch 42: val_accuracy did not improve from 0.96658\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9979 - loss: 0.0077 - val_accuracy: 0.9657 - val_loss: 0.1604 - learning_rate: 1.9531e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9986 - loss: 0.0056\n",
      "Epoch 43: val_accuracy did not improve from 0.96658\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9986 - loss: 0.0056 - val_accuracy: 0.9657 - val_loss: 0.1607 - learning_rate: 1.9531e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9977 - loss: 0.0069\n",
      "Epoch 44: val_accuracy did not improve from 0.96658\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9977 - loss: 0.0069 - val_accuracy: 0.9653 - val_loss: 0.1609 - learning_rate: 1.9531e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9988 - loss: 0.0065\n",
      "Epoch 45: val_accuracy did not improve from 0.96658\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9988 - loss: 0.0065 - val_accuracy: 0.9657 - val_loss: 0.1606 - learning_rate: 9.7656e-07\n",
      "Epoch 46/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9990 - loss: 0.0056\n",
      "Epoch 46: val_accuracy did not improve from 0.96658\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9990 - loss: 0.0056 - val_accuracy: 0.9657 - val_loss: 0.1606 - learning_rate: 9.7656e-07\n",
      "Epoch 47/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9980 - loss: 0.0058\n",
      "Epoch 47: val_accuracy did not improve from 0.96658\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.9657 - val_loss: 0.1610 - learning_rate: 9.7656e-07\n",
      "Epoch 48/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9967 - loss: 0.0095\n",
      "Epoch 48: val_accuracy did not improve from 0.96658\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9967 - loss: 0.0095 - val_accuracy: 0.9657 - val_loss: 0.1605 - learning_rate: 4.8828e-07\n",
      "Epoch 49/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9994 - loss: 0.0040\n",
      "Epoch 49: val_accuracy did not improve from 0.96658\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9994 - loss: 0.0040 - val_accuracy: 0.9657 - val_loss: 0.1606 - learning_rate: 4.8828e-07\n",
      "Epoch 50/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9989 - loss: 0.0058\n",
      "Epoch 50: val_accuracy did not improve from 0.96658\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9989 - loss: 0.0058 - val_accuracy: 0.9657 - val_loss: 0.1606 - learning_rate: 4.8828e-07\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "checkpoint = ModelCheckpoint(\"emotion_detection_crnn_attention.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
    "history = emotion_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[checkpoint, lr_scheduler],\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba073766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T18:27:11.743824Z",
     "iopub.status.busy": "2025-07-29T18:27:11.743015Z",
     "iopub.status.idle": "2025-07-29T18:27:12.536755Z",
     "shell.execute_reply": "2025-07-29T18:27:12.535931Z"
    },
    "papermill": {
     "duration": 1.449321,
     "end_time": "2025-07-29T18:27:12.538185",
     "exception": false,
     "start_time": "2025-07-29T18:27:11.088864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion_model.save(\"emotions_model.keras\", save_format=\"keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c44a2eb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T18:27:13.815707Z",
     "iopub.status.busy": "2025-07-29T18:27:13.815417Z",
     "iopub.status.idle": "2025-07-29T18:27:16.760260Z",
     "shell.execute_reply": "2025-07-29T18:27:16.759418Z"
    },
    "papermill": {
     "duration": 3.627068,
     "end_time": "2025-07-29T18:27:16.761667",
     "exception": false,
     "start_time": "2025-07-29T18:27:13.134599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       1.00      0.97      0.98       307\n",
      "        calm       0.96      0.97      0.97       307\n",
      "     disgust       0.96      0.96      0.96       307\n",
      "     fearful       0.98      0.95      0.97       307\n",
      "       happy       0.98      0.98      0.98       307\n",
      "     neutral       0.87      0.98      0.92       154\n",
      "         sad       0.94      0.95      0.95       307\n",
      "   surprised       0.98      0.98      0.98       308\n",
      "\n",
      "    accuracy                           0.97      2304\n",
      "   macro avg       0.96      0.97      0.96      2304\n",
      "weighted avg       0.97      0.97      0.97      2304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION\n",
    "y_pred = emotion_model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test_int, y_pred_labels, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd1072bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T18:27:18.015894Z",
     "iopub.status.busy": "2025-07-29T18:27:18.015617Z",
     "iopub.status.idle": "2025-07-29T18:27:19.310233Z",
     "shell.execute_reply": "2025-07-29T18:27:19.309628Z"
    },
    "papermill": {
     "duration": 1.947908,
     "end_time": "2025-07-29T18:27:19.311312",
     "exception": false,
     "start_time": "2025-07-29T18:27:17.363404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step\n",
      "Actual: angry, Predicted: surprised\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Actual: disgust, Predicted: disgust\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Actual: angry, Predicted: neutral\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Actual: fearful, Predicted: fearful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Actual: sad, Predicted: sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Actual: angry, Predicted: angry\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Actual: calm, Predicted: calm\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Actual: calm, Predicted: calm\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Actual: disgust, Predicted: disgust\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Actual: happy, Predicted: happy\n"
     ]
    }
   ],
   "source": [
    "# RANDOM PREDICTIONS\n",
    "indices = random.sample(range(len(X_test)), 10)\n",
    "for idx in indices:\n",
    "    pred = emotion_model.predict(np.expand_dims(X_test[idx], axis=0))[0]\n",
    "    actual = le.classes_[np.argmax(y_test[idx])]\n",
    "    predicted = le.classes_[np.argmax(pred)]\n",
    "    print(f\"Actual: {actual}, Predicted: {predicted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bb68641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T18:27:20.501557Z",
     "iopub.status.busy": "2025-07-29T18:27:20.501239Z",
     "iopub.status.idle": "2025-07-29T18:27:20.749606Z",
     "shell.execute_reply": "2025-07-29T18:27:20.748972Z"
    },
    "papermill": {
     "duration": 0.841253,
     "end_time": "2025-07-29T18:27:20.750786",
     "exception": false,
     "start_time": "2025-07-29T18:27:19.909533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# PLOT ACCURACY\n",
    "# -----------------------------\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 107620,
     "sourceId": 256618,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1743.087491,
   "end_time": "2025-07-29T18:27:24.990577",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-29T17:58:21.903086",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
